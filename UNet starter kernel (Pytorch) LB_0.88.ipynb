{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet starter for Steel defect detection challenge\n",
    "\n",
    "\n",
    "This kernel uses a UNet model with pretrained resnet18 encoder for this challenge, with simple augmentations using albumentations library, uses BCE loss, metrics like Dice and IoU. I've used [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) which comes with a lot pre-implemented segmentation architectures. This is a modified version of my previous [kernel](https://www.kaggle.com/rishabhiitbhu/unet-with-resnet34-encoder-pytorch) for [siim-acr-pneumothorax-segmentation](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/) competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As internet is not allowed for this competition, I tried installing `segmentation_models.pytorch` by source using pip but due to some reasons it didn't work. So, as a [Jugaad](https://en.wikipedia.org/wiki/Jugaad) I took all of `segmentation_models.pytorch`'s UNet code and wrote it in a single file and added it as a dataset so as to use it for this kernel, its dependency [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch) is also added as a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install ../input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/ > /dev/null # no output\n",
    "package_path = '../input/unetmodelscript' # add unet script dataset\n",
    "import sys\n",
    "sys.path.append(package_path)\n",
    "from model import Unet # import Unet model from the script, modelã£ã¦ã©ã“ã§è¨­å®šã•ã‚ŒãŸã‚“ã "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.torch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img): #ã“ã®kernelã§ã¯ä½¿ã£ã¦ãªã„(å¤šåˆ†)\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name #ilocã¯seriesã‚’è¿”ã—ã€ãã®seriesã®nameã¯ã‚‚ã¨ã®è¡Œã®index\n",
    "    labels = df.iloc[row_id][:4] #defectsã‚’é™¤ã„ãŸseries\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp(â†what is V.Imp) \n",
    "    # 4:class 1ï½4 (ch:0ï½3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values): #labels.valuesã¯1Ã—4ã®np.arrayã§è¦ç´ ã¯encoded pixels\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \") #ä¸€ã¤ã®ã‚¯ãƒ©ã‚¹ã®encoded pixelsã‚’ç¸¦ã«ã²ãŸã™ã‚‰ä¸¦ã¹ãŸã‚„ã¤\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8) #ã“ã‚Œã¯ä¸€æ¬¡å…ƒé…åˆ—\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1 #å‚·ã‚ã‚‹ã¨ã“ã‚ã‚’1ã«ã—ã¦mask\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F') #order=\"F\"ã«ã—ã¦ä¸€æ¬¡å…ƒé…åˆ—ã‚’ç¸¦ã«ä¸¦ã¹ã¦ã„ã\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist() #imageidã®ãƒªã‚¹ãƒˆ\n",
    "\n",
    "    def __getitem__(self, idx): #idxã¯æ•°å­—\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask) #list_trfmsã¯maskã‚‚targetã¨ã—ã¦å–ã‚‹\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask #imgã¯1Ã—1(3?)Ã—256Ã—1600\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                HorizontalFlip(p=0.5), # only horizontal flip as of now,ä¸­å¿ƒè»¸ã«é–¢ã—ã¦ç¢ºç‡0.5ã§å¯¾ç§°ç§»å‹•\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Normalize(mean=mean, std=std, p=1), #meanã‚’å¼•ã„ã¦stdã§å‰²ã‚‹(?)\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "    df['ClassId'] = df['ClassId'].astype(int)\n",
    "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1) #è¡Œã”ã¨ã®nanã˜ã‚ƒãªã„ã¨ã“ã‚ã®æ•°\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more utility functions\n",
    "\n",
    "Dice and IoU metric implementations, metric logger for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8') #thredholdã‚ˆã‚Šå¤§ãã„ã¨ã“ã‚ã¯1\n",
    "    return preds\n",
    "\n",
    "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately''' #é™½æ€§é™°æ€§ã®positive,negative(?)\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    batch_size = len(truth) #truthã¯batch_sizeÃ—4Ã—256Ã—1600ãªã®ã§lenã¯batch_size\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1) #torch.Size([batch_size,4Ã—256Ã—1600])ï¼‰(äºŒæ¬¡å…ƒé…åˆ—ã«ã™ã‚‹)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float() # thresholdã‚’è¶…ãˆã¦ã‚‹ã¨ã“ã‚ãŒ1ã»ã‹ã¯0ã®torch.Tensor,torch.Size([batch_size,4Ã—256Ã—1600])\n",
    "                                              # å„è¡ŒãŒå†™çœŸä¸€æšã«å¯¾å¿œ(?)\n",
    "                                              # ã“ã‚Œtorch.Size([batch_sizeÃ—4,256Ã—1600])ã—ã¦å„è¡Œã‚’ã‚ã‚‹å†™çœŸã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã•ã›ã‚‹ã¹ãã§ã¯?\n",
    "        t = (truth > 0.5).float() #ã“ã‚Œã„ã‚‹ã®ã‹?floatã«ã—ãŸã„ã ã‘?\n",
    "\n",
    "        t_sum = t.sum(-1) #è¡Œã”ã¨ã«è¶³ã—ç®—,torch.Size([1,batch_size])(æ¨ªãƒ™ã‚¯ãƒˆãƒ«)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0) # t_sumãŒ0ã®ã¨ã“ã‚ã®ä½ç½®,torch.Size([hoge,1])(ç¸¦ãƒ™ã‚¯ãƒˆãƒ«)ã€‚\n",
    "                                              # è¦ã™ã‚‹ã«ä¸€ã¤ã‚‚å‚·ãŒãªã„å†™çœŸã®batchå†…ã§ã®index(0~batch_size-1)\n",
    "        pos_index = torch.nonzero(t_sum >= 1) # å‚·ãŒä¸€ã¤ä»¥ä¸Šã‚ã‚‹å†™çœŸã®batchå†…ã§ã®index\n",
    "        \n",
    "        dice_neg = (p_sum == 0).float() # å‚·ãŒã‚ã‚‹å†™çœŸã¯0,ç„¡ã„å†™çœŸã¯1ã€‚torch.Size([1,batch_size])\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1)) # åˆ†æ¯0ã«ãªã‚Šã†ã‚‹ã®ã§ã¯?,torch.Size([1,batch_size])\n",
    "                                                     # è¦ç´ ã¯ãã‚Œãã‚Œã®å†™çœŸã®dice_score(ãŸã ã—tã«1ãŒå«ã¾ã‚Œã‚‹ã¨ãã®ã¿æ„å‘³ã‚’æŒã¤)\n",
    "\n",
    "        dice_neg = dice_neg[neg_index] \n",
    "        dice_pos = dice_pos[pos_index] \n",
    "        dice = torch.cat([dice_pos, dice_neg]) #torch.Size([1,batch_size])ãŸã ã—ä¸¦ã³é †ã¯t_sumã‚„p_sumã¨ã¯ç•°ãªã‚‹\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0) # .mean()ã§å¹³å‡ã‚’å–ã£ã¦.item()ã§tensorã‹ã‚‰numberã«ã™ã‚‹,nanãªã‚‰0ã«ç›´ã™\n",
    "                                                            # nanã¯åˆ†æ¯ãŒ0ã ã£ãŸã¨ãã«ç™ºç”Ÿ?\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "        \n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.base_dice_scores = []\n",
    "        self.dice_neg_scores = []\n",
    "        self.dice_pos_scores = []\n",
    "        self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs): #dice,dice_neg,dice_pos,iouã®ãƒªã‚¹ãƒˆã‚’æ›´æ–°\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
    "        self.base_dice_scores.append(dice)\n",
    "        self.dice_pos_scores.append(dice_pos)\n",
    "        self.dice_neg_scores.append(dice_neg)\n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        dice = np.mean(self.base_dice_scores)\n",
    "        dice_neg = np.mean(self.dice_neg_scores)\n",
    "        dice_pos = np.mean(self.dice_pos_scores)\n",
    "        dices = [dice, dice_neg, dice_pos]\n",
    "        iou = np.nanmean(self.iou_scores)\n",
    "        return dices, iou\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    dices, iou = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n",
    "    return dice, iou\n",
    "\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True): #pred,labelã®shapeã¯(4,256,1600)\n",
    "    '''computes iou for one ground truth mask and predicted mask'''\n",
    "    pred[label == ignore_index] = 0 #labelã«255ã®ã¨ã“ã‚ã¨ã‹ã‚ã‚‹ã®?ã™ã¹ã¦0or1ã§ã¯?\n",
    "    ious = []\n",
    "    for c in classes: #classes=[1]\n",
    "        label_c = label == c # c=1ãªã‚‰å¤‰åŒ–ãªã—ã€c=0ãªã‚‰01ãŒåè»¢\n",
    "        if only_present and np.sum(label_c) == 0: #np.sum(label_c)ã¯c=1ãªã‚‰labelã®ãªã‹ã®1ã®æ•°,np.sum(label_c)==0ãªã‚‰å‚·ãªã—\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum() \n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union) #IoUã‚’è¨ˆç®—\n",
    "    return ious if ious else [1] # if iousã¨ã¯,iousãŒç©ºãªã‚‰[1]ã‚’è¿”ã™?\n",
    "\n",
    "def compute_iou_batch(outputs, labels, classes=None): #ã“ã‚Œã«ã¤ã„ã¦ã‚‚ç”»åƒã”ã¨ã§ã¯ãªãã¦ç”»åƒã®ã•ã‚‰ã«1ã‚¯ãƒ©ã‚¹ã”ã¨ã«ã‚„ã‚‹ã¹ã?\n",
    "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
    "    ious = []\n",
    "    preds = np.copy(outputs) # copy is imp(impã¨ã¯),np.shape(batch_size,4,256,1600)\n",
    "    labels = np.array(labels) # tensor to np, labelsã¯æ­£è§£ã®mask\n",
    "    for pred, label in zip(preds, labels): #pred,labelã®shapeã¯(4,256,1600)\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes))) #np.nanmeanã¯nanã‚’é™¤å¤–ã—ãŸå¹³å‡\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/.cache/torch/checkpoints/\n",
    "!cp ../input/resnet18/resnet18.pth /tmp/.cache/torch/checkpoints/resnet18-5c106cde.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model # a *deeper* look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 6\n",
    "        self.batch_size = {\"train\": 4, \"val\": 4}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train'] \n",
    "        self.lr = 5e-4\n",
    "        self.num_epochs = 20\n",
    "        self.best_loss = float(\"inf\") #ç„¡é™å¤§ã§åˆæœŸåŒ–\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss() #loss_funcã¯ã‚ã‚‹ã‚„ã¤ã‚’ä½¿ã†(diceã«ã—ã¡ã‚ƒã†?)ã“ã„ã¤ã¯å†…éƒ¨çš„ã«sigmoidã‚’æŒŸã‚“ã§ã‚‹?\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                df_path=train_df_path,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406), #ã“ã“ã‚’è¦‹ã‚‹ã¨colorãªæ„Ÿã˜ã ã‘ã©ã©ã†ãªã‚“ã ã‚ã†\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        masks = targets.to(self.device)\n",
    "        outputs = self.net(images) #ã“ã®ã¨ãoutputsã¯batch_sizeÃ—4Ã—256Ã—1600\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch) #meterã¯epochã”ã¨ã«ä½œã‚Šå¤‰ãˆã‚‹(ãã‚Œã¯ãã†)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | â°: {start}\")\n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\") #tain_modeã«ã™ã‚‹ã‹ã©ã†ã‹\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "#         tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
    "            images, targets = batch #imagesã¯batch_sizeÃ—1Ã—256Ã—1600(grayscale?),targetsã¯batch_sizeÃ—4Ã—256Ã—1600(å¤šåˆ†)\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad() #æœ€é©åŒ–ã‚’å®Ÿè¡Œã™ã‚‹ã®ã¯accumulateã—ã¦ã‹ã‚‰(defaultã§ã¯8epochã”ã¨)\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        self.iou_scores[phase].append(iou)\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, \"./model.pth\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\n",
    "train_df_path = '../input/severstal-steel-defect-detection/train.csv'\n",
    "data_folder = \"../input/severstal-steel-defect-detection/\"\n",
    "test_data_folder = \"../input/severstal-steel-defect-detection/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING\n",
    "losses = model_trainer.losses\n",
    "dice_scores = model_trainer.dice_scores # overall dice\n",
    "iou_scores = model_trainer.iou_scores\n",
    "\n",
    "def plot(scores, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
    "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
    "    plt.legend(); \n",
    "    plt.show()\n",
    "\n",
    "plot(losses, \"BCE loss\")\n",
    "plot(dice_scores, \"Dice score\")\n",
    "plot(iou_scores, \"IoU score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction and submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training and validation takes about ~400 minutes which exceeds Kaggle's GPU usage limit of 60 minutes, we won't be able to submit the `submission.csv` file generated from this kernel. So, for test prediction and submission I've written a separate [UNet inference kernel](https://www.kaggle.com/rishabhiitbhu/unet-pytorch-inference-kernel), make sure you add the `model.pth` file generated from this kernel as dataset to test inference kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've used resnet-18 architecture in this kernel. It scores ~0.89 on LB. Try to play around with other architectures of `segmenation_models.pytorch` and see what works best for you, let me know in the comments :) and do upvote if you liked this kernel, I need some medals too. ğŸ˜¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "\n",
    "Few kernels from which I've borrowed some cod[](http://)e:\n",
    "\n",
    "* https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "* https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n",
    "\n",
    "A big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https://www.kaggle.com/abhishek), [@Yury](https://www.kaggle.com/deyury), [@Heng](https://www.kaggle.com/hengck23), [@Ekhtiar](https://www.kaggle.com/ekhtiar), [@lafoss](https://www.kaggle.com/iafoss), [@Siddhartha](https://www.kaggle.com/meaninglesslives), [@xhulu](https://www.kaggle.com/xhlulu), and the list goes on.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
